{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09b4508",
   "metadata": {},
   "source": [
    "# 1. import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import Genome\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['methylation_data/GSM2039756_scTrio_HepG2_1_RRBS.single.CpG.txt',\n",
    "              'methylation_data/GSM2039758_scTrio_HepG2_2_RRBS.single.CpG.txt',\n",
    "              'methylation_data/GSM2039760_scTrio_HepG2_3_RRBS.single.CpG.txt',\n",
    "              'methylation_data/GSM2039762_scTrio_HepG2_4_RRBS.single.CpG.txt',\n",
    "              'methylation_data/GSM2039764_scTrio_HepG2_5_RRBS.single.CpG.txt',\n",
    "              'methylation_data/GSM2039766_scTrio_HepG2_6_RRBS.single.CpG.txt'        \n",
    "             ]\n",
    "chro=0\n",
    "position=1\n",
    "strand=3\n",
    "read=4\n",
    "label=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f26bc",
   "metadata": {},
   "source": [
    "# 2. Select data with 4 reads or more and only necessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(file_paths, chro, position, strand, read, label):\n",
    "    \"\"\"\n",
    "    Reads and processes methylation data from the given file paths, extracts the necessary columns, \n",
    "    and saves them as separate CSV files.\n",
    "    :param file_paths: List of file paths\n",
    "    :param chro: Index of the chromosome column\n",
    "    :param position: Index of the position column\n",
    "    :param strand: Index of the strand column\n",
    "    :param read: number of total reads\n",
    "    :param label: Index of the label column\n",
    "    \"\"\"\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        # Read the file\n",
    "        data_frame = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "        # Select data with 4 reads or more\n",
    "        processed_data_frame=data_frame[data_frame[read]>=4]\n",
    "        # select only necessary columns\n",
    "        selected_columns = processed_data_frame[[chro, position, strand, label]]\n",
    "        \n",
    "        # Reindex and convert data types\n",
    "        selected_columns.columns = ['chro', 'position', 'strand', 'label']\n",
    "        selected_columns['label'] = selected_columns['label'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        \n",
    "        # Save the selected columns to a csv file\n",
    "        output_file_path = f'picked_columns_HepG2_cell{i+1}.csv'\n",
    "        selected_columns.to_csv(output_file_path, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e331b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_save(file_paths, chro, position, strand, read, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01f4da",
   "metadata": {},
   "source": [
    "# 3. define basic things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c760aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list for chromosomes\n",
    "chromosomes = ['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10',\n",
    "               'chr11','chr12','chr13','chr14','chr15', 'chr16','chr17', 'chr18','chr19', 'chr20',\n",
    "               'chr21','chr22']\n",
    "\n",
    "# define columns for generated files with only necessary columns\n",
    "chro_col=0\n",
    "position_col=1\n",
    "strand_col=2\n",
    "label_col=3\n",
    "number_of_cells=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5707d",
   "metadata": {},
   "source": [
    "# 4. read processed files and split them per cells and chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facfe094",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=['picked_columns_HepG2_cell1.csv',\n",
    "      'picked_columns_HepG2_cell2.csv',\n",
    "      'picked_columns_HepG2_cell3.csv',\n",
    "      'picked_columns_HepG2_cell4.csv',\n",
    "      'picked_columns_HepG2_cell5.csv',\n",
    "      'picked_columns_HepG2_cell6.csv',\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(files, chromosomes, chro_col, position_col, label_col): \n",
    "    for i, file in enumerate(files):\n",
    "        data_frame=pd.read_csv(file, sep='\\t', header=None)\n",
    "        for chromosome in chromosomes:\n",
    "            \n",
    "            #split the file per cell and chromosomes\n",
    "            data_frame_chr=data_frame[data_frame[chro_col]==chromosome]\n",
    "            output_file_path='HepG2_cell'+str(i+1)+'_'+chromosome+'.csv'\n",
    "            data_frame_chr.to_csv(output_file_path, sep='\\t', index=False, header=False)\n",
    "            \n",
    "            #make dictionary for positions and label\n",
    "            position_label=dict(zip(data_frame_chr[position_col], data_frame_chr[label_col]))\n",
    "            with open ('label_HepG2_cell'+str(i+1)+'_'+chromosome+'.pkl', 'wb') as f:\n",
    "                pickle.dump(position_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23952b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(files, chromosomes, chro_col, position_col, label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3aaf10",
   "metadata": {},
   "source": [
    "# 5. combine positions of all cells per chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae636fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positions(number_of_cells, chromosomes, position_col):\n",
    "    for chromosome in chromosomes:\n",
    "        combined_positions=[]\n",
    "        for i in range(number_of_cells):\n",
    "            data_frame=pd.read_csv('HepG2_cell'+str(i+1)+'_'+chromosome+'.csv', sep='\\t', header=None)\n",
    "            positions=list(data_frame[position_col])\n",
    "            combined_positions.extend(positions)\n",
    "        unique_sorted_positions=sorted(set(combined_positions))\n",
    "        with open (\"position_all_HepG2_\"+chromosome+\".pkl\", \"wb\") as f:\n",
    "            pickle.dump(unique_sorted_positions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions(number_of_cells, chromosomes, position_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fe439",
   "metadata": {},
   "source": [
    "# 6. Imin&Imax (ranges to be covered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Iminmax(number_of_cells, chromosomes, position_col):\n",
    "    Imin=[]\n",
    "    Imax=[]\n",
    "    for chromosome in chromosomes:\n",
    "        value_begin=[]\n",
    "        value_end=[]\n",
    "        \n",
    "        for i in range(number_of_cells):\n",
    "            data_frame=pd.read_csv('HepG2_cell'+str(i+1)+'_'+chromosome+'.csv', sep='\\t', header=None)\n",
    "            begin=data_frame[position_col][50]\n",
    "            end=data_frame[position_col][len(data_frame)-51]\n",
    "            value_begin.append(begin)\n",
    "            value_end.append(end)\n",
    "        imin=max(value_begin)\n",
    "        imax=min(value_end)\n",
    "        Imin.append(imin)\n",
    "        Imax.append(imax)\n",
    "\n",
    "    with open (\"Imin_HepG2.pkl\", \"wb\") as g:\n",
    "        pickle.dump(Imin, g)\n",
    "    with open (\"Imax_HepG2.pkl\", \"wb\") as h:\n",
    "        pickle.dump(Imax, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Iminmax(number_of_cells, chromosomes, position_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f74415",
   "metadata": {},
   "source": [
    "# 7. For DNA features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d607c",
   "metadata": {},
   "source": [
    "# 7.1. extract one-hot encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb63b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(seq):\n",
    "    bases={'A':[1,0,0,0], 'T':[0,1,0,0], 'G':[0,0,1,0], 'C':[0,0,0,1], 'N':[0,0,0,0]}\n",
    "    a=[]\n",
    "    for i in range(len(seq)):\n",
    "        b=seq[i]\n",
    "        c=bases[b]\n",
    "        a.append(c)\n",
    "    return a\n",
    "\n",
    "\n",
    "def extr_seq(dna_size, number_of_cells, chromosomes, position_col, strand_col): #encoding method ==one-hot\n",
    "    with open(\"Imin_HepG2.pkl\", \"rb\") as f1:\n",
    "        Imin=pickle.load(f1)\n",
    "    with open(\"Imax_HepG2.pkl\", \"rb\") as f2:\n",
    "        Imax=pickle.load(f2)\n",
    "        \n",
    "    g=Genome.Genome('genome_data/hg19.fa')\n",
    "    \n",
    "    for i in range(number_of_cells):\n",
    "        for j, chromosome in enumerate (chromosomes):\n",
    "            imin=Imin[j]\n",
    "            imax=Imax[j]\n",
    "            a= pd.read_csv('HepG2_cell'+str(i+1)+'_'+chromosome+'.csv', sep='\\t', header=None)\n",
    "            dna_seq=[]\n",
    "            position=[]\n",
    "            for k in a.index:\n",
    "                item=a[position_col][k]\n",
    "                if imin <= item <=imax:\n",
    "                    if a[strand_col][k]=='+':\n",
    "                        seq=g.get_seq(chromosome, item-1-dna_size, item+dna_size, '+')\n",
    "                        onehot_seq=onehot(seq)\n",
    "                    elif a[strand_col][k]=='-':\n",
    "                        seq=g.get_seq(chromosome, item-1-dna_size, item+dna_size, '-')\n",
    "                        onehot_seq=onehot(seq)\n",
    "                    dna_seq.append(onehot_seq)\n",
    "                    position.append(item)\n",
    "            pos_seq=dict(zip(position, dna_seq))\n",
    "            with open('dna_feature/onehot_HepG2_cell'+str(i+1)+'_'+chromosome+'.pkl', 'wb') as h:\n",
    "                pickle.dump(pos_seq, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_size=25 # the length of nucelotide: (dna_sizex2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35aa1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_seq(dna_size, number_of_cells, chromosomes, position_col, strand_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc458ec",
   "metadata": {},
   "source": [
    "# 8. For CpG features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6334f",
   "metadata": {},
   "source": [
    "# 8.1. data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed834042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpg_augment(chromosomes, number_of_cells, position_col, label_col):\n",
    "\n",
    "    for chromosome in chromosomes:\n",
    "        cpg_map=[]\n",
    "        \n",
    "        # Read all CSV files in advance and store them in memory\n",
    "        cell_data={}\n",
    "        for i in range(number_of_cells):\n",
    "            data_frame=pd.read_csv('HepG2_cell'+str(i+1)+'_'+chromosome+'.csv', sep='\\t', header=None)\n",
    "            cell_data[i]=data_frame\n",
    "        \n",
    "        with open (\"position_all_HepG2_\"+chromosome+\".pkl\", \"rb\") as f:\n",
    "            position_all=pickle.load(f)\n",
    "            for j in position_all:\n",
    "                position=[j]\n",
    "                for k in range(number_of_cells):\n",
    "                    a=cell_data[k]\n",
    "                    if (a[position_col]==j).any()==True:\n",
    "                        index=np.argmax(a[1]==j)\n",
    "                        if a[label_col][index]==1:\n",
    "                            sub=[1,0]\n",
    "                        if a[label_col][index]==0:\n",
    "                            sub=[0,1]\n",
    "                        position.extend(sub)\n",
    "                    else:\n",
    "                        sub=[0,0]\n",
    "                        position.extend(sub)\n",
    "                cpg_map.append(position)\n",
    "        np.save('cpg_map_HepG2_'+chromosome, cpg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_augment(chromosomes, number_of_cells, position_col, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61b482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680a4dbd",
   "metadata": {},
   "source": [
    "# 8.2. intercellular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercellular(number_of_cells, chromosomes, position_col): #i=cell_no, j=chromosome_no\n",
    "    with open(\"Imin_HepG2.pkl\", \"rb\") as f1:\n",
    "        Imin=pickle.load(f1)\n",
    "    with open(\"Imax_HepG2.pkl\", \"rb\") as f2:\n",
    "        Imax=pickle.load(f2)\n",
    "            \n",
    "    def process_cell(cell_no, chromosome, imin, imax, positions_map, states_map, pos_col):\n",
    "        a= pd.read_csv('HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.csv', sep='\\t', header=None) \n",
    "        positions=[]\n",
    "        states=[]\n",
    "        for k in a.index:\n",
    "            item=a[pos_col][k]\n",
    "            if imin <= item <=imax:\n",
    "                index=positions_map.get(item)\n",
    "                intercellular=np.delete(states_map[index],cell_no,axis=0).tolist()\n",
    "                positions.append(item)\n",
    "                states.append(intercellular)\n",
    "        pos_state=dict(zip(positions,states))\n",
    "        with open ('cpg_feature/intercellular_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'wb') as h:\n",
    "            pickle.dump(pos_state, h)\n",
    "            \n",
    "    for j, chromosome in enumerate (chromosomes):\n",
    "        imin=Imin[j]\n",
    "        imax=Imax[j]\n",
    "        pos_col=position_col\n",
    "        cpg_map=np.load('cpg_map_HepG2_'+chromosome+'.npy')\n",
    "        positions_map= {pos: idx for idx, pos in enumerate(cpg_map[:, 0])}\n",
    "        states_map=cpg_map[:,1:].reshape(-1,number_of_cells,2)\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(process_cell, i, chromosome, imin, imax, positions_map, states_map, pos_col) for i in range(number_of_cells)]\n",
    "            for future in futures:\n",
    "                future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab40a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercellular(number_of_cells, chromosomes, position_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03122441",
   "metadata": {},
   "source": [
    "# 8.2. intracellular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49863181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intracellular(number_of_cells, chromosomes, intra_size, position_col):\n",
    "    with open(\"Imin_HepG2.pkl\", \"rb\") as f1:\n",
    "        Imin=pickle.load(f1)\n",
    "    with open(\"Imax_HepG2.pkl\", \"rb\") as f2:\n",
    "        Imax=pickle.load(f2)\n",
    "    \n",
    "    def process_cell(cell_no, chromosome, imin, imax, positions_map, states_map, pos_col):\n",
    "        a= pd.read_csv('HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.csv', sep='\\t', header=None) \n",
    "        positions=[]\n",
    "        states=[] \n",
    "        for k in a.index:\n",
    "            item=a[pos_col][k]\n",
    "            if imin <= item <=imax:\n",
    "                index=positions_map.get(item)\n",
    "                same_cell=states_map[index-intra_size:index+intra_size+1,cell_no]\n",
    "                intracellular=np.delete(same_cell,intra_size, axis=0).tolist()\n",
    "                positions.append(item)\n",
    "                states.append(intracellular)\n",
    "        pos_state=dict(zip(positions,states))\n",
    "        with open ('cpg_feature/intracellular_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'wb') as h:\n",
    "            pickle.dump(pos_state, h)    \n",
    "    \n",
    "    \n",
    "    for j, chromosome in enumerate (chromosomes):\n",
    "        imin=Imin[j]\n",
    "        imax=Imax[j]\n",
    "        pos_col=position_col\n",
    "        cpg_map=np.load('cpg_map_HepG2_'+chromosome+'.npy')\n",
    "        positions_map= {pos: idx for idx, pos in enumerate(cpg_map[:, 0])}\n",
    "        states_map=cpg_map[:,1:].reshape(-1,number_of_cells,2)\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(process_cell, i, chromosome, imin, imax, positions_map, states_map, pos_col) for i in range(number_of_cells)]\n",
    "            for future in futures:\n",
    "                future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1137dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_size=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981737ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "intracellular(number_of_cells, chromosomes, length, position_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a6bff",
   "metadata": {},
   "source": [
    "# 9. Extract all features per cell/chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be212796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features(number_of_cells, chromosomes, position_col):\n",
    "    with open(\"Imin_HepG2.pkl\", \"rb\") as f1:\n",
    "        Imin=pickle.load(f1)\n",
    "    with open(\"Imax_HepG2.pkl\", \"rb\") as f2:\n",
    "        Imax=pickle.load(f2)\n",
    "    \n",
    "    for cell_no in range(number_of_cells):\n",
    "        for j, chromosome in enumerate (chromosomes):\n",
    "            a= pd.read_csv('HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.csv', sep='\\t', header=None) \n",
    "            \n",
    "            with open('dna_feature/onehot_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'rb') as h:\n",
    "                b=pickle.load(h)\n",
    "            with open ('cpg_feature/intercellular_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'rb') as k:\n",
    "                c=pickle.load(k)\n",
    "            with open ('cpg_feature/intracellular_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'rb') as l:\n",
    "                d=pickle.load(l)\n",
    "            with open ('label_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'rb') as m:\n",
    "                e=pickle.load(m)\n",
    "            imin=Imin[j]\n",
    "            imax=Imax[j]\n",
    "            all_dna=[]\n",
    "            all_inter=[]\n",
    "            all_intra=[]\n",
    "            all_label=[]\n",
    "            for n in a.index:\n",
    "                item=a[position_col][n]\n",
    "                if imin <= item <=imax:\n",
    "                    dna=b[item]\n",
    "                    inter=c[item]\n",
    "                    intra=d[item]\n",
    "                    label=e[item]\n",
    "                    all_dna.append(dna)\n",
    "                    all_inter.append(inter)\n",
    "                    all_intra.append(intra)\n",
    "                    all_label.append(label)\n",
    "            dna_array=np.asarray(all_dna, dtype=np.float)\n",
    "            inter_array=np.asarray(all_inter, dtype=np.float)\n",
    "            intra_array=np.asarray(all_intra, dtype=np.float)\n",
    "            label_array=np.asarray(all_label, dtype=np.float)\n",
    "            all_features=[dna_array, inter_array, intra_array, label_array]\n",
    "            \n",
    "            with open ('all_features/all_features_HepG2_cell'+str(cell_no+1)+'_'+chromosome+'.pkl', 'wb') as o:\n",
    "                pickle.dump(all_features, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features(number_of_cells, chromosomes, position_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c742c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acfebf47",
   "metadata": {},
   "source": [
    "# 10. making training, test, validation set for each cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=[1,3,5,7,9,11]\n",
    "test_set=[2,4,6,8,10,12]\n",
    "validation_set=[13,14,15,16,17,18,19]# data\n",
    "\n",
    "def dataset(number_of_cells, training_set, test_set, validation_set, dna_size, intra_size):\n",
    "    \n",
    "    for cell_no in range(number_of_cells):\n",
    "        \n",
    "        x1_train=np.empty((0,dna_size*2+1,4), int)\n",
    "        x2_train=np.empty((0,number_of_cells-1,2), int)\n",
    "        x3_train=np.empty((0,intra_size*2,2), int)\n",
    "        y_train=np.empty((0), int)\n",
    "\n",
    "        x1_test=np.empty((0,dna_size*2+1,4), int)\n",
    "        x2_test=np.empty((0,number_of_cells-1,2), int)\n",
    "        x3_test=np.empty((0,intra_size*2,2), int)\n",
    "        y_test=np.empty((0), int)\n",
    "\n",
    "        x1_val=np.empty((0,dna_size*2+1,4), int)\n",
    "        x2_val=np.empty((0,number_of_cells-1,2), int)\n",
    "        x3_val=np.empty((0,intra_size*2,2), int)\n",
    "        y_val=np.empty((0), int)\n",
    "        \n",
    "        \n",
    "        for j in training_set:\n",
    "            with open('all_features/all_features_HepG2_cell'+str(cell_no+1)+'_chr'+str(j)+'.pkl', 'rb') as f:\n",
    "                a=pickle.load(f)\n",
    "                x1_train=np.append(x1_train, a[0], axis=0)\n",
    "                x2_train=np.append(x2_train, a[1], axis=0)\n",
    "                x3_train=np.append(x3_train, a[2], axis=0)\n",
    "                y_train=np.append(y_train, a[3])\n",
    "        train=[x1_train, x2_train, x3_train, y_train]\n",
    "        with open ('training_set_HepG2_cell'+str(cell_no+1)+'.pkl', 'wb') as g:\n",
    "            pickle.dump(train, g)\n",
    "        \n",
    "        for j in test_set:\n",
    "            with open('all_features/all_features_HepG2_cell'+str(cell_no+1)+'_chr'+str(j)+'.pkl', 'rb') as f:\n",
    "                a=pickle.load(f)\n",
    "                x1_test=np.append(x1_test, a[0], axis=0)\n",
    "                x2_test=np.append(x2_test, a[1], axis=0)\n",
    "                x3_test=np.append(x3_test, a[2], axis=0)\n",
    "                y_test=np.append(y_test, a[3])\n",
    "        test=[x1_test, x2_test, x3_test, y_test]\n",
    "        with open ('test_set_HepG2_cell'+str(cell_no+1)+'.pkl', 'wb') as g:\n",
    "            pickle.dump(test, g)\n",
    "            \n",
    "            \n",
    "        for j in validation_set:\n",
    "            with open('all_features/all_features_HepG2_cell'+str(cell_no+1)+'_chr'+str(j)+'.pkl', 'rb') as f:\n",
    "                a=pickle.load(f)\n",
    "                x1_val=np.append(x1_val, a[0], axis=0)\n",
    "                x2_val=np.append(x2_val, a[1], axis=0)\n",
    "                x3_val=np.append(x3_val, a[2], axis=0)\n",
    "                y_val=np.append(y_val, a[3])\n",
    "        val=[x1_val, x2_val, x3_val, y_val]\n",
    "        with open ('val_set_HepG2_cell'+str(cell_no+1)+'.pkl', 'wb') as g:\n",
    "            pickle.dump(val, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset(number_of_cells, training_set, test_set, validation_set, dna_size, intra_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb782f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, LSTM, MaxPooling1D, Conv1D, Flatten, Dropout, Permute, Activation, Lambda, multiply\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454dc1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d38f919",
   "metadata": {},
   "source": [
    "# 11. Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e1d76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, LSTM, MaxPooling1D, Conv1D, Flatten, Dropout, Permute, Activation, Lambda, multiply\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CpGFuse_model():\n",
    "    \n",
    "    input1=keras.layers.Input(shape=(dna_size*2+1,4))\n",
    "    x1 = Conv1D(filters=32,kernel_size=5, strides=1,activation='relu',padding='same')(input1)\n",
    "    print(x1)\n",
    "    attention1 = Dense(16)(x1)\n",
    "    attention1 = Permute((2, 1))(attention1)\n",
    "    attention1 = Activation('softmax')(attention1)\n",
    "    attention1 = Permute((2, 1))(attention1)\n",
    "    attention1 = Lambda(lambda x: K.mean(x, axis=2), name='attention1',output_shape=(51,))(attention1)\n",
    "    attention1 = RepeatVector(32)(attention1)\n",
    "    attention1 = Permute((2,1))(attention1)\n",
    "    x1_multiply = multiply([x1, attention1])\n",
    "    x1 = Flatten()(x1_multiply)\n",
    "                \n",
    "    input2 = keras.layers.Input(shape=(number_of_cells-1,2))\n",
    "    x2=input2\n",
    "    x2 = Flatten()(x2)\n",
    "                \n",
    "    input3 = keras.layers.Input(shape=(intra_size*2,2))\n",
    "    x3 = Conv1D(filters=32, kernel_size=5,strides=1,activation='relu',padding='same')(input3)\n",
    "    attention3 = Dense(50)(x3)\n",
    "    attention3 = Permute((2, 1))(attention3)\n",
    "    attention3 = Activation('softmax')(attention3)\n",
    "    attention3 = Permute((2, 1))(attention3)\n",
    "    attention3 = Lambda(lambda x: K.mean(x, axis=2), name='attention3',output_shape=(50,))(attention3)\n",
    "    attention3 = RepeatVector(32)(attention3)\n",
    "    attention3 = Permute((2,1))(attention3)\n",
    "    x3_multiply = multiply([x3, attention3])\n",
    "    x3 = Flatten()(x3_multiply)\n",
    "\n",
    "    merge=keras.layers.concatenate([x1,x2, x3], axis=-1)\n",
    "    drop = Dropout(0.3)(merge)\n",
    "    dense = Dense(16, activation= 'relu')(drop)\n",
    "    out=keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input1, input2, input3], outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b39b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CpGFuse_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374013ab",
   "metadata": {},
   "source": [
    "# 12. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "def train_and_evaluation(number_of_cells):\n",
    "    for i in range(number_of_cells):\n",
    "        with open('training_set_HepG2_cell'+str(i+1)+'.pkl', 'rb') as f:\n",
    "            train=pickle.load(f)\n",
    "            x1_train=train[0]\n",
    "            x2_train=train[1]\n",
    "            x3_train=train[2]\n",
    "            y_train=train[3]\n",
    "        with open('test_set_HepG2_cell'+str(i+1)+'.pkl', 'rb') as f:\n",
    "            test=pickle.load(f)\n",
    "            x1_test=test[0]\n",
    "            x2_test=test[1]\n",
    "            x3_test=test[2]\n",
    "            y_test=test[3]\n",
    "        with open('val_set_HepG2_cell'+str(i+1)+'.pkl', 'rb') as f:\n",
    "            val=pickle.load(f)\n",
    "            x1_val=val[0]\n",
    "            x2_val=val[1]\n",
    "            x3_val=val[2]\n",
    "            y_val=val[3]\n",
    "            \n",
    "        # Model Initialization    \n",
    "        model = CpGFuse_model()\n",
    "        \n",
    "        filename='best_cpgfuse_HepG2_cell'+str(i+1)+'.h5'\n",
    "        checkpoint=ModelCheckpoint(filename,\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=0,\n",
    "                                   save_best_only=True,\n",
    "                                   mode='min')\n",
    "        earlystopping= EarlyStopping(monitor='val_loss',\n",
    "                                     patience=10)\n",
    "\n",
    "        op= tf.keras.optimizers.SGD(learning_rate= 0.05) #RMS, prop, SGD, \n",
    "        model.compile(loss='binary_crossentropy',optimizer= op, metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit([x1_train,x2_train, x3_train],y_train, batch_size=32, epochs=80, validation_data =([x1_val, x2_val, x3_val], y_val), callbacks=[checkpoint, earlystopping])\n",
    "        model.load_weights(filename)\n",
    "        \n",
    "        loss, accuracy = model.evaluate([x1_test, x2_test, x3_test], y_test)\n",
    "        \n",
    "        print(f'Test Loss for cell {i + 1}: {loss}')\n",
    "        print(f'Test Accuracy for cell {i + 1}: {accuracy}')\n",
    "        \n",
    "        y_pred = model.predict([x1_test, x2_test, x3_test])\n",
    "        y_pred_edit = np.where(y_pred >= 0.5, 1, 0)\n",
    "        y_pred_edit = y_pred_edit.reshape(-1,)\n",
    "        cm = confusion_matrix(y_test, y_pred_edit)\n",
    "        print('Confusion Matrix : \\n', cm)\n",
    "        # [0,0]: true negative\n",
    "        # [0,1]: false positive\n",
    "        # [1,0]: false negative\n",
    "        # [1,1]: true positive\n",
    "        \n",
    "        total=sum(sum(cm))\n",
    "        \n",
    "        #####from confusion matrix calculate accuracy\n",
    "        accuracy=(cm[0,0]+cm[1,1])/total\n",
    "        print ('Accuracy_cell'+str(i+1)+' : ', accuracy)\n",
    "        sensitivity = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "        print('Sensitivity_cell'+str(i+1)+' : ', sensitivity )\n",
    "        specificity = cm[0,0]/(cm[0,1]+cm[0,0])\n",
    "        print('Specificity_cell'+str(i+1)+' : ', specificity)\n",
    "        precision = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "        print('Precision_cell'+str(i+1)+' : ', precision)\n",
    "        print('MCC_cell'+str(i+1)+' : ', matthews_corrcoef(y_test, y_pred_edit))\n",
    "        print('f1_score_cell'+str(i+1)+' : ', f1_score(y_test,y_pred_edit))\n",
    "        \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "        AUROC=metrics.auc(fpr, tpr)\n",
    "        print('ROC AUC_cell'+str(i+1)+' : ', AUROC)\n",
    "        pr_auc = average_precision_score(y_test, y_pred)\n",
    "        print('PR AUC_cell'+str(i+1)+' : ', pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluation(number_of_cells)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
